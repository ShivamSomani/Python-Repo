{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Building a neural network of a single layer\n",
    "import numpy as np\n",
    "from numpy import exp,array,random,dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        #seeding the random number generator\n",
    "        random.seed(1)\n",
    "        #modelling a single neuron with 3 inputs and 1 output, assign random weights\n",
    "        #in range -1 to 1 to a 3 X 1 matrixand mean 0\n",
    "        self.synaptic_weights = 2*random.random((3,1)) - 1\n",
    "    #defining the activation function, weighted sum of inputs is \n",
    "    #passed through it and it gets normalised b/w 0 and 1\n",
    "    def __sigmoid(self,x):\n",
    "        return (1/(1 + exp(-x)))\n",
    "    def predict(self,inputs):\n",
    "        #pass inputs through the neural network(single neuron)\n",
    "        return self.__sigmoid(dot(inputs,self.synaptic_weights))\n",
    "    #gradient of sigmoid curve\n",
    "    def __sigmoid_derivative(self,x):\n",
    "        return x * (1-x)\n",
    "    def train(self,inputs,ioutputs,iterations):\n",
    "        for iteration in xrange(iterations):\n",
    "            output = self.predict(inputs)\n",
    "            #calculate error\n",
    "            error = ioutputs - output\n",
    "            #multiplying the error by input and gradient of the sigmoid curve\n",
    "            #less confident weights are adjusted more\n",
    "            adjustment = dot(inputs.T, error*self.__sigmoid_derivative(output))\n",
    "            #adjust the weights\n",
    "            self.synaptic_weights += adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synaptic Weights are:\n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "New Synaptic Weights after training:\n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n",
      "Output for [0,0,1] is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.009664])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialise a single neuron neural network\n",
    "nn = NeuralNetwork()\n",
    "print(\"Synaptic Weights are:\")\n",
    "print nn.synaptic_weights\n",
    "#defining the training set with 3 input and 1 output value\n",
    "x_train = array([[0,0,1],[1,1,1],[1,0,1],[0,1,1]])\n",
    "y_train = array([[0,1,1,0]]).T\n",
    "#train the neural network using the training set, we can do it for a number\n",
    "#of iterations\n",
    "nn.train(x_train,y_train,10000)\n",
    "print(\"New Synaptic Weights after training:\")\n",
    "print nn.synaptic_weights\n",
    "print(\"Output for [0,0,1] is:\")\n",
    "nn.predict(array([0,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#expanding the neural network for more number of layers\n",
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        #seeding the random number generator\n",
    "        random.seed(1)\n",
    "        #Defining the number of nodes in subsequent layers\n",
    "        l2 = 5\n",
    "        l3 = 7\n",
    "        l4 = 8\n",
    "        l5 = 4\n",
    "        # assign random weights to matrices in network\n",
    "        # format is (no. of nodes in previous layer) x (no. of nodes in following layer)\n",
    "        self.synaptic_weights1 = 2 * random.random((3, l2)) -1\n",
    "        self.synaptic_weights2 = 2 * random.random((l2, l3)) -1\n",
    "        self.synaptic_weights3 = 2 * random.random((l3, l4)) -1\n",
    "        self.synaptic_weights4 = 2 * random.random((l4, l5)) -1\n",
    "        self.synaptic_weights5 = 2 * random.random((l5, 1)) -1\n",
    "    #defining the activation function, weighted sum of inputs is \n",
    "    #passed through it and it gets normalised b/w 0 and 1\n",
    "    def __sigmoid(self,x):\n",
    "        return (1/(1 + exp(-x)))\n",
    "    #gradient of sigmoid curve\n",
    "    def __sigmoid_derivative(self,x):\n",
    "        return x * (1-x)\n",
    "    #passing the inputs through the different layers of the neural network\n",
    "    def predict(self,inputs):\n",
    "        f2 = self.__sigmoid(dot(inputs, self.synaptic_weights1))\n",
    "        f3 = self.__sigmoid(dot(f2, self.synaptic_weights2))\n",
    "        f4 = self.__sigmoid(dot(f3, self.synaptic_weights3))\n",
    "        f5 = self.__sigmoid(dot(f4, self.synaptic_weights4))\n",
    "        output = self.__sigmoid(dot(f5, self.synaptic_weights5))\n",
    "        return output\n",
    "    def train(self,inputs,ioutputs,iterations):\n",
    "        for iteration in xrange(iterations):\n",
    "            #passing the training set through the neural network \n",
    "            #through the successive layers\n",
    "            f2 = self.__sigmoid(dot(inputs, self.synaptic_weights1))\n",
    "            f3 = self.__sigmoid(dot(f2, self.synaptic_weights2))\n",
    "            f4 = self.__sigmoid(dot(f3, self.synaptic_weights3))\n",
    "            f5 = self.__sigmoid(dot(f4, self.synaptic_weights4))\n",
    "            output = self.__sigmoid(dot(f5, self.synaptic_weights5))\n",
    "            #error calculation and backpropagation\n",
    "            del6 = (ioutputs - output)*self.__sigmoid_derivative(output)\n",
    "            del5 = dot(self.synaptic_weights5, del6.T)*(self.__sigmoid_derivative(f5).T)\n",
    "            del4 = dot(self.synaptic_weights4, del5.T)*(self.__sigmoid_derivative(f4).T)\n",
    "            del3 = dot(self.synaptic_weights3, del4)*(self.__sigmoid_derivative(f3).T)\n",
    "            del2 = dot(self.synaptic_weights2, del3)*(self.__sigmoid_derivative(f2).T)\n",
    "            #calculation of the adjustments of each layer\n",
    "            adjustment5 = dot(f5.T, del6)\n",
    "            adjustment4 = dot(f4.T, del5.T)\n",
    "            adjustment3 = dot(f3.T, del4.T)\n",
    "            adjustment2 = dot(f2.T, del3.T)\n",
    "            adjustment1 = dot(inputs.T, del2.T)\n",
    "            #adjusting the weights\n",
    "            self.synaptic_weights1 += adjustment1\n",
    "            self.synaptic_weights2 += adjustment2\n",
    "            self.synaptic_weights3 += adjustment3\n",
    "            self.synaptic_weights4 += adjustment4\n",
    "            self.synaptic_weights5 += adjustment5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synaptic Weights of layer 1 are:\n",
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485 -0.70648822]\n",
      " [-0.81532281 -0.62747958 -0.30887855 -0.20646505  0.07763347]\n",
      " [-0.16161097  0.370439   -0.5910955   0.75623487 -0.94522481]]\n",
      "Synaptic Weights of layer 2 are:\n",
      "[[ 0.34093502 -0.1653904   0.11737966 -0.71922612 -0.60379702  0.60148914\n",
      "   0.93652315]\n",
      " [-0.37315164  0.38464523  0.7527783   0.78921333 -0.82991158 -0.92189043\n",
      "  -0.66033916]\n",
      " [ 0.75628501 -0.80330633 -0.15778475  0.91577906  0.06633057  0.38375423\n",
      "  -0.36896874]\n",
      " [ 0.37300186  0.66925134 -0.96342345  0.50028863  0.97772218  0.49633131\n",
      "  -0.43911202]\n",
      " [ 0.57855866 -0.79354799 -0.10421295  0.81719101 -0.4127717  -0.42444932\n",
      "  -0.73994286]]\n",
      "Synaptic Weights of layer 3 are:\n",
      "[[-0.96126608  0.35767107 -0.57674377 -0.46890668 -0.01685368 -0.89327491\n",
      "   0.14823521 -0.70654285]\n",
      " [ 0.17861107  0.39951672 -0.79533114 -0.17188802  0.38880032 -0.17164146\n",
      "  -0.90009308  0.07179281]\n",
      " [ 0.32758929  0.02977822  0.88918951  0.17311008  0.80680383 -0.72505059\n",
      "  -0.72144731  0.61478258]\n",
      " [-0.20464633 -0.66929161  0.85501716 -0.30446828  0.50162421  0.45199597\n",
      "   0.76661218  0.24734441]\n",
      " [ 0.50188487 -0.30220332 -0.46014422  0.79177244 -0.14381762  0.92968009\n",
      "   0.326883    0.24339144]\n",
      " [-0.77050805  0.89897852 -0.10017573  0.15677923 -0.18372639 -0.52594604\n",
      "   0.80675904  0.14735897]\n",
      " [-0.99425935  0.23428983 -0.3467102   0.0541162   0.7718842  -0.28546048\n",
      "   0.8170703   0.24672023]]\n",
      "Synaptic Weights of layer 4 are:\n",
      "[[-0.96835751  0.85887447  0.38179384  0.9946457 ]\n",
      " [-0.65531898 -0.7257285   0.86519093  0.39363632]\n",
      " [-0.86799965  0.51092611  0.50775238  0.84604907]\n",
      " [ 0.42304952 -0.75145808 -0.96023973 -0.94757803]\n",
      " [-0.94338702 -0.50757786  0.7200559   0.07766213]\n",
      " [ 0.10564396  0.68406178 -0.75165337 -0.44163264]\n",
      " [ 0.17151854  0.9391915   0.12206044 -0.96270542]\n",
      " [ 0.60126535 -0.53405145  0.61421039 -0.22427871]]\n",
      "Synaptic Weights of layer 5 are:\n",
      "[[ 0.72708371]\n",
      " [ 0.49424329]\n",
      " [ 0.11248047]\n",
      " [-0.72708955]]\n",
      "New Synaptic Weights of layer 1 are:\n",
      "[[ 0.87222184  1.71878825 -0.59365616 -2.53300287 -0.43529661]\n",
      " [-1.502457   -2.77250596 -0.43687941  3.0748712  -0.30520635]\n",
      " [-0.1712361  -0.40290787 -0.41227533  1.18524818 -0.87861264]]\n",
      "New Synaptic Weights of layer 2 are:\n",
      "[[-0.55147983 -1.32104879  0.15959366 -0.11652783 -1.26692993  0.07821768\n",
      "   0.95250626]\n",
      " [-1.70720741 -1.43408989  0.86444943  1.54116647 -1.99810236 -1.77568068\n",
      "  -0.69454972]\n",
      " [ 0.62544293 -0.87890064 -0.22054271  1.05848071  0.16887148  0.32072915\n",
      "  -0.38220158]\n",
      " [ 1.7117262   2.86298584 -0.61143402  0.61423139  3.13929009  1.50978745\n",
      "  -0.19014443]\n",
      " [ 0.53040643 -0.79596039 -0.14038331  0.90366056 -0.27470488 -0.45037106\n",
      "  -0.74287861]]\n",
      "New Synaptic Weights of layer 3 are:\n",
      "[[-1.48535969 -0.43616687 -1.18869678  0.17863503 -1.1331713  -1.37152171\n",
      "  -1.13482657 -0.1963363 ]\n",
      " [-0.48202641 -0.46971311 -1.57651838  0.63521006 -0.7683207  -0.79673254\n",
      "  -2.73567786  0.80724064]\n",
      " [ 0.35898736 -0.61699733  1.59677559  0.24299762 -0.32855332 -0.54221866\n",
      "   1.06320097 -0.130835  ]\n",
      " [-0.47659103 -1.71165747  0.98543133  0.12805112 -1.25662648  0.41752768\n",
      "   1.82203013 -0.3064963 ]\n",
      " [-0.35495722 -1.24932374 -1.84327409  1.82294891 -1.47000359  0.15209726\n",
      "  -2.27335185  1.24560506]\n",
      " [-1.30614456  0.09034498 -0.78875827  0.82739727 -1.34658249 -0.99349324\n",
      "  -0.40312797  0.61312313]\n",
      " [-1.20399045 -0.39688028 -0.32825683  0.36891528 -0.24801634 -0.37606387\n",
      "   1.21807216  0.04574826]]\n",
      "New Synaptic Weights of layer 4 are:\n",
      "[[-1.23296218 -0.29960556  1.17724358  1.4812282 ]\n",
      " [-1.0387602  -1.29197269  1.37134889  0.91545   ]\n",
      " [-1.49344801 -0.52802186  1.4413786   1.6797368 ]\n",
      " [ 0.73315604  0.2556359  -1.5909207  -0.91269152]\n",
      " [-1.58793417 -2.21966896  1.93993548  1.03915472]\n",
      " [-0.1785062   0.29943907 -0.40074825 -0.03367817]\n",
      " [-0.36629914  1.31055737  0.15483486 -0.52621295]\n",
      " [ 0.69806721 -0.66038873  0.66118409  0.17918676]]\n",
      "New Synaptic Weights of layer 5 are:\n",
      "[[-1.99628826]\n",
      " [-2.4083731 ]\n",
      " [ 3.28814661]\n",
      " [ 2.51230617]]\n",
      "Output for [0,0,1] is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.37772035])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialise a single neuron neural network\n",
    "nn = NeuralNetwork()\n",
    "print(\"Synaptic Weights of layer 1 are:\")\n",
    "print nn.synaptic_weights1\n",
    "print(\"Synaptic Weights of layer 2 are:\")\n",
    "print nn.synaptic_weights2\n",
    "print(\"Synaptic Weights of layer 3 are:\")\n",
    "print nn.synaptic_weights3\n",
    "print(\"Synaptic Weights of layer 4 are:\")\n",
    "print nn.synaptic_weights4\n",
    "print(\"Synaptic Weights of layer 5 are:\")\n",
    "print nn.synaptic_weights5\n",
    "#defining the training set with 3 input and 1 output value\n",
    "x_train = array([[0,0,1],[1,1,1],[1,0,1],[0,1,1]])\n",
    "y_train = array([[0,1,1,0]]).T\n",
    "nn.train(training_set_inputs, training_set_outputs, 2000)\n",
    "print(\"New Synaptic Weights of layer 1 are:\")\n",
    "print nn.synaptic_weights1\n",
    "print(\"New Synaptic Weights of layer 2 are:\")\n",
    "print nn.synaptic_weights2\n",
    "print(\"New Synaptic Weights of layer 3 are:\")\n",
    "print nn.synaptic_weights3\n",
    "print(\"New Synaptic Weights of layer 4 are:\")\n",
    "print nn.synaptic_weights4\n",
    "print(\"New Synaptic Weights of layer 5 are:\")\n",
    "print nn.synaptic_weights5\n",
    "print(\"Output for [0,0,1] is:\")\n",
    "nn.predict(array([0,0,1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
