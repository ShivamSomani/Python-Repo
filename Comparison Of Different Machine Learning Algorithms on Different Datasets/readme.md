# Comparing Different Machine Learning Algorithms on Different Datasets

## Library Used
scikit-learn

## Datasets Used

The following are the links of different datasets which have been used in the project:

1.Abalone Dataset
 
http://archive.ics.uci.edu/ml/datasets/Abalone 

2.Banknote Authentication Dataset 

http://archive.ics.uci.edu/ml/datasets/banknote+authentication 

3.Contraceptive Methods Dataset

http://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice 

4.Poker Hand Dataset 

http://archive.ics.uci.edu/ml/datasets/Poker+Hand 

5.Student Alcohol Consumption Dataset 

http://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION 

6.Skin Segmentation Dataset 

http://archive.ics.uci.edu/ml/datasets/Skin+Segmentation 

7.Wine Quality Dataset 

http://archive.ics.uci.edu/ml/datasets/Wine+Quality 

8.Tic-Tac-Toe Dataset 

https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame

## Algorithms Used (from sikit-learn library)
The following Machine Learning Algorithms have been implemented on them: 

1.K-Nearest Neighbors 

2.Random Forests Classifier 

3.Support Vector Machines 

4.Gaussian Naive Bayes Classifier 

5.Logistic Regression 

6.AdaBoost Classifier 

7.Stochastic Gradient Descent Classifier 

8.Decision Trees Classifier 

9.Linear Discriminant Analysis 

10.Gradient Boosting Classifier

Here, all algorithms have been implemented with their default parameters only. For furthur optimization of classification accuracy, we can use Parameter Tuning as it has been done in XGBoost.
